"""
Ephyra Chatbot - Production RAG (Retrieval Augmented Generation)
LLM-Based Architecture with Semantic Search, Keyword Search, and Gemini Generation
"""

from functools import lru_cache
import os
import io
import uuid
import logging
from pathlib import Path
from typing import AsyncGenerator, Optional, List, Dict, Tuple
from datetime import datetime, timedelta
import json
import psycopg2
import psycopg2.pool
import httpx
from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from elevenlabs.client import ElevenLabs
import re
from sentence_transformers import SentenceTransformer
from langdetect import detect, LangDetectException
from fastapi.middleware.cors import CORSMiddleware
import csv
import string

 
# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î¼Î¹Î± Î»Î¯ÏƒÏ„Î± Î³Î¹Î± Î½Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏƒÎ¿Ï…Î¼Îµ Ï„Î¹Ï‚ ÎµÏÏ‰Ï„Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
knowledge_base = []

# Î‘Î½Î¿Î¯Î³Î¿Ï…Î¼Îµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î±Î½Î­Î²Î±ÏƒÎµÏ‚ ÏƒÏ„Î¿ GitHub
with open("QA_chatbot.csv", mode="r", encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        knowledge_base.append(row)


# ================== Configuration ==================
load_dotenv(dotenv_path=Path(__file__).with_name(".env"), override=True)





logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
log = logging.getLogger("ephyra")

required_vars = ["OPENAI_API_KEY", "DB_NAME", "DB_USER", "DB_PASS", "DB_HOST"]
missing = [v for v in required_vars if not os.getenv(v)]
if missing:
    raise RuntimeError(f"Missing env vars: {', '.join(missing)}")

# Î•Î´Ï Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹Ï‚ Ï„Î·Î½ Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… OpenAI
from openai import OpenAI
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# ================== FastAPI Setup ==================
app = FastAPI(title="Ephyra Chatbot - Production RAG", version="3.0.0")
app.mount("/static", StaticFiles(directory="static"), name="static")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================== AUTO-SYNC CSV TO DATABASE ==================
def sync_csv_to_db():
    try:
        conn = psycopg2.connect(
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASS"),
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT", "5432")
        )
        cur = conn.cursor()

        # 1. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€Î¯Î½Î±ÎºÎ±
        cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        cur.execute("""
            CREATE TABLE IF NOT EXISTS public.kb_items_raw (
                id SERIAL PRIMARY KEY,
                question TEXT,
                answer TEXT,
                category TEXT,
                embedding_384 vector(384)
            );
        """)

        # 2. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
        log.info("ğŸ”„ Syncing CSV to DB...")
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

        # 3. ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ & Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘ Î•Î¥Î¡Î•Î¤Î—Î¡Î™ÎŸÎ¥ (HNSW) ğŸš€
        cur.execute("TRUNCATE public.kb_items_raw;")
        cur.execute("""
            CREATE INDEX IF NOT EXISTS kb_items_embedding_idx 
            ON public.kb_items_raw 
            USING hnsw (embedding_384 vector_cosine_ops);
        """)

        # 4. Î‘Î½Î­Î²Î±ÏƒÎ¼Î± Î±Ï€ÏŒ CSV
        with open("QA_chatbot.csv", mode="r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                values = list(row.values())
                if len(values) >= 2:
                    q, a = values[0], values[1]
                    emb = model.encode(q).tolist()
                    cur.execute(
                        "INSERT INTO kb_items_raw (question, answer, embedding_384) VALUES (%s, %s, %s)",
                        (q, a, emb)
                    )
        
        conn.commit()
        cur.close()
        conn.close()
        log.info("âœ… Database sync complete & Index created!")
    except Exception as e:
        log.error(f"âŒ Sync failed: {e}")


# ===============================================================

# Mount static files
try:
    static_dir = os.path.dirname(os.path.abspath(__file__))
    app.mount("/static", StaticFiles(directory=static_dir, check_dir=True), name="static")
except Exception as e:
    log.warning(f"âš ï¸ Could not mount static files: {e}")

# ================== Database ==================
try:
    conn_pool = psycopg2.pool.SimpleConnectionPool(
        5, 20,
        dbname=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASS"),
        host=os.getenv("DB_HOST"),
        port=os.getenv("DB_PORT", "5432"),
    )
    log.info("âœ… Database connection pool created")
except Exception as e:
    log.exception("âŒ Database connection failed")
    raise

# 1. Î— Î²Î±ÏƒÎ¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·
def get_db_conn():
    try:
        return conn_pool.getconn()
    except Exception as e:
        log.exception("âŒ Failed to get DB connection from pool")
        raise

# 2. Î— ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î®Ï‚
def return_db_conn(conn):
    if conn:
        try:
            conn_pool.putconn(conn)
        except Exception as e:
            log.error(f"âŒ Error returning connection to pool: {e}")

class SurveyResponse(BaseModel):
    usedBot: str
    usageContext: str
    scenarios: str
    gender: Optional[str] = "N/A"  # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ·
    age: Optional[str] = "N/A"     # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ·
    q1: int; q2: int; q3: int; q4: int; q5: int
    q6: int; q7: int; q8: int; q9: int; q10: int
    q11: int; q12: int; q13: int; q14: int; q15: int
    q16: int                       # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ·
    comments: Optional[str] = ""


# --- AYTOMATH Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘ Î Î™ÎÎ‘ÎšÎ‘ SURVEY ---
def init_survey_db():
    conn = get_db_conn() 
    cur = conn.cursor()
    try:
        # Î”Î¹Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ± Î³Î¹Î± Î½Î± ÎµÏ†Î±ÏÎ¼Î¿ÏƒÏ„Î¿ÏÎ½ Î¿Î¹ Î½Î­ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ ÏƒÏ‰ÏƒÏ„Î¬
        cur.execute("DROP TABLE IF EXISTS survey_final CASCADE;") 

        cur.execute("""
            CREATE TABLE IF NOT EXISTS survey_final (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                used_bot TEXT,
                usage_context TEXT,
                scenarios_tested TEXT, -- Î— ÏƒÏ„Î®Î»Î· Î³Î¹Î± Ï„Î± ÏƒÎµÎ½Î¬ÏÎ¹Î±
                gender TEXT,
                age TEXT,
                q1 INTEGER, q2 INTEGER, q3 INTEGER, q4 INTEGER, q5 INTEGER,
                q6 INTEGER, q7 INTEGER, q8 INTEGER, q9 INTEGER, q10 INTEGER,
                q11 INTEGER, q12 INTEGER, q13 INTEGER, q14 INTEGER, q15 INTEGER,
                q16 INTEGER,
                comments TEXT
            );
        """)
        conn.commit()
    except Exception as e:
        log.error(f"âŒ Error initializing survey table: {e}")
    finally:
        cur.close()
        return_db_conn(conn)

init_survey_db()

@app.post("/submit_survey")
async def submit_survey(data: SurveyResponse):
    conn = get_db_conn()
    cur = conn.cursor()
    try:
        # 22 ÏƒÏ„Î®Î»ÎµÏ‚ ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬
        query = """
            INSERT INTO survey_final 
            (used_bot, usage_context, scenarios_tested, gender, age, 
             q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, 
             q11, q12, q13, q14, q15, q16, comments)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        cur.execute(query, (
            data.usedBot,           # used_bot
            data.usageContext,      # usage_context
            data.scenarios,         # scenarios_tested (Î•Î”Î© ÎœÎ Î‘Î™ÎÎŸÎ¥Î Î¤Î‘ Î£Î•ÎÎ‘Î¡Î™Î‘)
            data.gender,            # gender
            data.age,               # age
            data.q1, data.q2, data.q3, data.q4, data.q5,
            data.q6, data.q7, data.q8, data.q9, data.q10,
            data.q11, data.q12, data.q13, data.q14, data.q15,
            data.q16,               # q16
            data.comments           # comments
        ))
        conn.commit()
        return {"status": "success"}
    except Exception as e:
        if conn: conn.rollback()
        log.error(f"âŒ Database Insertion Error: {e}")
        return {"status": "error", "message": str(e)}
    finally:
        cur.close()
        return_db_conn(conn)

 
# 3. Î¤Î± Aliases (Î³Î¹Î± Î½Î± Î¼Î· Ï‡Ï„Ï…Ï€Î¬ÎµÎ¹ Ï€Î¿Ï…Î¸ÎµÎ½Î¬ Î¿ ÎºÏÎ´Î¹ÎºÎ±Ï‚)
get_db_connection = get_db_conn
return_db_connection = return_db_conn

# 4. Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€Î¯Î½Î±ÎºÎ± feedback Î±Î½ Î»ÎµÎ¯Ï€ÎµÎ¹
def init_feedback_table():
    conn = None
    try:
        conn = get_db_conn()
        cursor = conn.cursor()
        
        # Î Î¡ÎŸÎ£ÎŸÎ§Î—: Î”Î¹Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ Ï€Î±Î»Î¹ÏŒ Ï€Î¯Î½Î±ÎºÎ± Î³Î¹Î± Î½Î± Ï„Î¿Î½ Î¾Î±Î½Î±Ï†Ï„Î¹Î¬Î¾Î¿Ï…Î¼Îµ ÏƒÏ‰ÏƒÏ„Î¬
        #cursor.execute("DROP TABLE IF EXISTS chatbot_feedback CASCADE;") 
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î¼Îµ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± Ï€Î¿Ï… Î¸Î­Î»Î¿Ï…Î½ Î¿Î¹ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ ÏƒÎ¿Ï… (timestamp ÎºÎ±Î¹ ip_address)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS chatbot_feedback (
                id SERIAL PRIMARY KEY,
                conversation_id TEXT,
                bot_response TEXT,
                user_question TEXT,
                is_positive BOOLEAN,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- ÎŸÎ½Î¿Î¼Î¬ÏƒÏ„Î·ÎºÎµ timestamp Î³Î¹Î± Ï„Î¿ Dashboard
                user_agent TEXT,
                ip_address TEXT  -- ÎŸÎ½Î¿Î¼Î¬ÏƒÏ„Î·ÎºÎµ ip_address Î³Î¹Î± Ï„Î¿ record_feedback
            );
        """)
        conn.commit()
        log.info("ğŸš€ Database Table 'chatbot_feedback' is now PERFECT!")
    except Exception as e:
        log.error(f"âŒ Error initializing table: {e}")
    finally:
        if conn:
            return_db_conn(conn)

init_feedback_table()

# ================== Embeddings (Lazy Load) ==================
embedder = None

@lru_cache(maxsize=1)
def get_embedder():
    global embedder
    if embedder is None:
        log.info("ğŸ“„ Loading SentenceTransformer (first use)...")
        embedder = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
        log.info("âœ… SentenceTransformer loaded")
    return embedder

# ================== ElevenLabs Setup ==================
from elevenlabs.client import ElevenLabs

ELEVENLABS_API_KEY = (os.getenv("ELEVENLABS_API_KEY") or "").strip()
ELEVENLABS_VOICE_ID = (os.getenv("ELEVENLABS_VOICE_ID") or "EXAVITQu4vr4xnSDxMaL").strip()
eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
# ================== Pydantic Models ==================
class Message(BaseModel):
    role: str
    content: str

class AskBody(BaseModel):
    messages: List[Message]
    top_k: int = 10  # Changed from 5 to 10 for better coverage
    lang: str = "el"

class TTSBody(BaseModel):
    text: str

class FeedbackBody(BaseModel):
    bot_response: str
    user_question: str
    is_positive: bool
    conversation_id: str

# ================== Helper Functions ==================

def detect_user_lang(text: str) -> str:
    """Detect user language."""
    try:
        lang = detect((text or "").strip())
        return "en" if lang and lang.startswith("en") else "el"
    except LangDetectException:
        return "el"

def is_greeting(text: str) -> bool:
    """Check if text is a greeting."""
    greetings = ['Î³ÎµÎ¯Î±', 'Î³ÎµÎ¹Î±', 'ÎºÎ±Î»Î·Î¼Î­ÏÎ±', 'ÎºÎ±Î»Î·Î¼ÎµÏÎ±', 'ÎºÎ±Î»Î·ÏƒÏ€Î­ÏÎ±', 'ÎºÎ±Î»Î·ÏƒÏ€ÎµÏÎ±',
                 'Ï‡Î¬Î¹ÏÎµÏ„Îµ', 'Ï‡Î±Î¹ÏÎµÏ„Îµ', 'hello', 'hi', 'good morning', 'good evening']
    text_lower = text.lower().strip()
    return any(text_lower.startswith(g) or text_lower == g for g in greetings)

def get_direct_answer(question: str) -> Optional[Dict]:
    """Return direct answers for common questions that semantic search might miss."""
    text_lower = question.lower().strip()
    
    # ÎšÎ•Î  - ÎÏÎµÏ‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±Ï‚
    if any(kw in text_lower for kw in ['ÎºÎµÏ€', 'ÎºÎ­Î½Ï„ÏÎ¿ ÎµÎ¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ·Ï‚ Ï€Î¿Î»Î¹Ï„ÏÎ½', 'center']):
        if any(kw in text_lower for kw in ['ÏÏÎµÏ‚', 'Ï‰ÏÎ¬ÏÎ¹Î¿', 'Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³', 'hours', 'time', 'when', 'Ï€ÏŒÏ„Îµ']):
            return {
                "answer": """ÎšÎ•Î  ÎšÎ¿ÏÎ¯Î½Î¸Î¿Ï… - Î©ÏÎ¬ÏÎ¹Î¿ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±Ï‚

ğŸ“ Î”Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·: ÎšÏ‰ÏƒÏ„Î® Î Î±Î»Î±Î¼Î¬ 53, 20131 ÎšÏŒÏÎ¹Î½Î¸Î¿Ï‚

ğŸ•’ Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ± - Î Î±ÏÎ±ÏƒÎºÎµÏ…Î®, 8:00 - 15:00
         (Î¤ÎµÏ„Î¬ÏÏ„Î· ÎµÏ€Î¯ÏƒÎ·Ï‚ 17:00 - 19:00)

ğŸ“ Î¤Î·Î»Î­Ï†Ï‰Î½Î¿: 2741363555
ğŸ“§ Email: n.korinthias@kep.gov.gr""",
                "quality": "direct_match",
                "context_found": True,
                "confidence": 0.95
            }
        # ÎšÎ•Î  - Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚
        if any(kw in text_lower for kw in ['Ï„Î·Î»Î­Ï†Ï‰Î½Î¿', 'Ï„Î·Î»', 'email', 'address', 'Î´Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·', 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±']):
            return {
                "answer": """ÎšÎ•Î  ÎšÎ¿ÏÎ¯Î½Î¸Î¿Ï… - Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚

ğŸ“ Î”Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·: ÎšÏ‰ÏƒÏ„Î® Î Î±Î»Î±Î¼Î¬ 53, 20131 ÎšÏŒÏÎ¹Î½Î¸Î¿Ï‚

ğŸ“ Î¤Î·Î»Î­Ï†Ï‰Î½Î¿: 2741363555
ğŸ“§ Email: n.korinthias@kep.gov.gr

ğŸ•’ Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ± - Î Î±ÏÎ±ÏƒÎºÎµÏ…Î® 8:00-15:00""",
                "quality": "direct_match",
                "context_found": True,
                "confidence": 0.95
            }
    
    # Î”Î•Î¥Î‘ - Multiple variations
    if any(kw in text_lower for kw in ['Î´ÎµÏ…Î±', 'Î´.Îµ.Ï….Î±', 'water', 'Î½ÎµÏÏŒ']):
        if any(kw in text_lower for kw in ['Ï„Î·Î»Î­Ï†Ï‰Î½Î¿', 'Ï„Î·Î»', 'ÎºÎ»Î®ÏƒÎ·', 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'call', 'phone']):
            return {
                "answer": """Î”Î•Î¥Î‘ ÎšÎ¿ÏÎ¯Î½Î¸Î¿Ï…
ğŸ“ Î¤Î·Î»Î­Ï†Ï‰Î½Î¿ ÎšÎ­Î½Ï„ÏÎ¿: 2741024444
ğŸ“ Î’Î»Î¬Î²ÎµÏ‚ (24Ï‰ÏÎ¿): 6936776041
ğŸ“§ Email: info@deyakor.gr""",
                "quality": "direct_match",
                "context_found": True,
                "confidence": 0.95
            }
    
    # Î”Î®Î¼Î±ÏÏ‡Î¿Ï‚ - Multiple variations
    if any(kw in text_lower for kw in ['Î´Î®Î¼Î±ÏÏ‡', 'Î´Î·Î¼Î±ÏÏ‡', 'mayor', 'Î±ÏÏ‡Î·Î³']):
        if any(kw in text_lower for kw in ['Ï„Î·Î»Î­Ï†Ï‰Î½Î¿', 'Ï„Î·Î»', 'email', 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±', 'contact']):
            return {
                "answer": """Î“ÏÎ±Ï†ÎµÎ¯Î¿ Î”Î·Î¼Î¬ÏÏ‡Î¿Ï… ÎšÎ¿ÏÎ¹Î½Î¸Î¯Ï‰Î½

Î”Î®Î¼Î±ÏÏ‡Î¿Ï‚: ÎÎ¯ÎºÎ¿Ï‚ Î£Ï„Î±Ï…ÏÎ­Î»Î·Ï‚

ğŸ“ Î¤Î·Î»Î­Ï†Ï‰Î½Î¿: 27413-61001, 27413-61041
ğŸ“§ Email: grafeiodimarxou@korinthos.gr

ğŸ“ Î”Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·: ÎšÎ¿Î»Î¹Î¬Ï„ÏƒÎ¿Ï… 32, 201 31 ÎšÏŒÏÎ¹Î½Î¸Î¿Ï‚""",
                "quality": "direct_match",
                "context_found": True,
                "confidence": 0.95
            }
    
    # Î¤Î·Î»Î­Ï†Ï‰Î½Î± Î”Î®Î¼Î¿Ï… - Multiple variations
    if any(kw in text_lower for kw in ['Ï„Î·Î»Î­Ï†Ï‰Î½Î± Î´Î®Î¼Î¿Ï…', 'Î´Î·Î¼Î¿ÏƒÎ¹Î¿ Ï„Î·Î»', 'Î´Î·Î¼Î¿Ï‚ ÎºÎ¿ÏÎ¹Î½Î¸', 'ÎºÎ»Î®ÏƒÎ· Î´Î®Î¼Î¿Ï…', 'phone municipality']):
        if any(kw in text_lower for kw in ['Ï„Î·Î»', 'ÎºÎ­Î½Ï„ÏÎ¿', 'ÎºÎ»Î®ÏƒÎ·', 'phone', 'call', 'contact']):
            return {
                "answer": """Î¤Î·Î»ÎµÏ†Ï‰Î½Î¹ÎºÏŒ ÎšÎ­Î½Ï„ÏÎ¿ Î”Î®Î¼Î¿Ï… ÎšÎ¿ÏÎ¹Î½Î¸Î¯Ï‰Î½
ğŸ“ 27413-61000 (ÎšÏÏÎ¹Î± Î³ÏÎ±Î¼Î¼Î®)
ğŸ“ 27413-61040 (Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®)
ğŸ“ 27413-61045 (Î“ÏÎ±Ï†ÎµÎ¯Î¿ Î¤ÏÏ€Î¿Ï…)

Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ±-Î Î±ÏÎ±ÏƒÎºÎµÏ…Î® 8:00-14:00

Î“Î¹Î± Î±Î¹Ï„Î®Î¼Î±Ï„Î±: protokollo@korinthos.gr""",
                "quality": "direct_match",
                "context_found": True,
                "confidence": 0.95
            }
    
    return None
    """Check if user is asking about bot's capabilities."""
    text_lower = text.lower().strip()
    capability_keywords = [
        'Ï„Î¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚', 'Ï€Î¿Î¹ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚', 'Ï„Î¹ Î¼Ï€Î¿ÏÎµÎ¹Ï‚', 'Ï„Î¹ Î´Ï…Î½Î±Ï„Î¿Ï„Î·Ï„ÎµÏ‚',
        'Î¼Ï€Î¿ÏÎµÎ¹Ï‚ Î½Î± ÎºÎ±Î½ÎµÎ¹Ï‚', 'Î¼Ï€Î¿ÏÎµÎ¹Ï‚ Î½Î± Î¼Î¿Ï… Ï€Î±ÏÎµÏ‡ÎµÎ¹Ï‚', 'Î²Î¿Î·Î¸Î±', 'Î²Î¿Î·Î¸Î·ÏƒÎµÎ¹Ï‚',
        'what can you help', 'what information', 'what capabilities', 'can you help'
    ]
    return any(kw in text_lower for kw in capability_keywords)

def get_capabilities_response(lang: str = "el") -> str:
    """Return bot capabilities response - compact version with titles only."""
    if lang == "en":
        return """As a digital assistant for the Municipality of Corinth, I can help with:

1) Municipal Phone Numbers
2) Certificate Issuance
3) Registry Acts
4) Municipal History
5) General Municipal Services

For more information, visit https://korinthos.gr/"""
    else:
        return """Î©Ï‚ ÏˆÎ·Ï†Î¹Î±ÎºÏŒÏ‚ Î²Î¿Î·Î¸ÏŒÏ‚ Ï„Î¿Ï… Î”Î®Î¼Î¿Ï… ÎšÎ¿ÏÎ¹Î½Î¸Î¯Ï‰Î½, Î¼Ï€Î¿ÏÏ Î½Î± ÏƒÎ±Ï‚ Î´ÏÏƒÏ‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î±:

1) Î¤Î·Î»Î­Ï†Ï‰Î½Î± Ï„Î¿Ï… Î”Î®Î¼Î¿Ï…
2) ÎˆÎºÎ´Î¿ÏƒÎ· Î Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Ï„Î¹ÎºÏÎ½
3) Î›Î·Î¾Î¹Î±ÏÏ‡Î¹ÎºÎ­Ï‚ Î ÏÎ¬Î¾ÎµÎ¹Ï‚
4) Î™ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î”Î®Î¼Î¿Ï…
5) Î”Î·Î¼Î¿Ï„Î¹ÎºÎ­Ï‚ Î¥Ï€Î·ÏÎµÏƒÎ¯ÎµÏ‚

Î“Î¹Î± Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚, ÎµÏ€Î¹ÏƒÎºÎµÏ†Î¸ÎµÎ¯Ï„Îµ https://korinthos.gr/"""

def is_capabilities_question(text: str) -> bool:
    """Check if user is asking about bot's capabilities."""
    text_lower = text.lower().strip()
    capability_keywords = [
        'Ï„Î¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚', 'Ï€Î¿Î¹ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚', 'Ï„Î¹ Î¼Ï€Î¿ÏÎµÎ¹Ï‚', 'Ï„Î¹ Î´Ï…Î½Î±Ï„Î¿Ï„Î·Ï„ÎµÏ‚',
        'Î¼Ï€Î¿ÏÎµÎ¹Ï‚ Î½Î± ÎºÎ±Î½ÎµÎ¹Ï‚', 'Î¼Ï€Î¿ÏÎµÎ¹Ï‚ Î½Î± Î¼Î¿Ï… Ï€Î±ÏÎµÏ‡ÎµÎ¹Ï‚', 'Î²Î¿Î·Î¸Î±', 'Î²Î¿Î·Î¸Î·ÏƒÎµÎ¹Ï‚',
        'what can you help', 'what information', 'what capabilities', 'can you help',
        'Ï„Î¹ Î¾ÎµÏÎµÎ¹Ï‚', 'Ï„Î¹ Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹Ï‚', 'Î³Î¹Î± Ï„Î¹', 'ÏƒÏ‡ÎµÏ„Î¹ÎºÎ± Î¼Îµ Ï„Î¹'
    ]
    return any(kw in text_lower for kw in capability_keywords)

def is_out_of_scope(text: str) -> bool:
    """Check if question is out of scope. Be lenient - let RAG decide."""
    text_lower = text.lower().strip()
    
    # Scope keywords - if ANY of these are present, it's IN scope
    scope_keywords = [
        'Î´Î®Î¼Î¿Ï‚', 'ÎºÎ¿ÏÎ¯Î½Î¸', 'Ï„Î·Î»Î­Ï†Ï‰Î½Î¿', 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'Ï€Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Ï„Î¹ÎºÏŒ',
        'Î³Î­Î½Î½Î·ÏƒÎ·Ï‚', 'Î¸Î±Î½Î¬Ï„Î¿Ï…', 'Î³Î¬Î¼Î¿Ï…', 'Î»Î·Î¾Î¹Î±ÏÏ‡Î¹ÎºÎ­Ï‚', 'Î¼ÎµÏ„Î±Î´Î·Î¼ÏŒÏ„ÎµÏ…ÏƒÎ·',
        'Ï…Ï€Î·ÏÎµÏƒÎ¯Î±', 'Î´Î·Î¼Î±ÏÏ‡', 'Î±Î¯Ï„Î·ÏƒÎ·', 'Î­Î³Î³ÏÎ±Ï†Î¿', 'Ï‰ÏÎ¬ÏÎ¹Î¿', 'gov.gr',
        'ÎµÎºÎ´Î¿ÏƒÎ·', 'Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ±', 'Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±', 'Ï€ÏÎ¿Ï‹Ï€Î¿Î¸Î­ÏƒÎµÎ¹Ï‚', 'Î²Î®Î¼Î±Ï„Î±',
        'municipality', 'corinth', 'certificate', 'service', 'process'
    ]
    
    # If ANY keyword is present, it's likely IN scope - let RAG decide
    if any(kw in text_lower for kw in scope_keywords):
        return False  # IN SCOPE - let RAG handle it
    
    # Very obviously out of scope
    clearly_out_of_scope = [
        'weather', 'ÎºÎ±Î¹ÏÏŒÏ‚', 'football', 'Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿', 'recipe', 'ÏƒÏ…Î½Ï„Î±Î³Î®',
        'movie', 'Ï„Î±Î¹Î½Î¯Î±', 'politics', 'Ï€Î¿Î»Î¹Ï„Î¹ÎºÎ®', 'celebrity', 'ÏƒÎµÎ»Î­Î¼Ï€ÏÎ¹Ï„Î¹'
    ]
    
    if any(kw in text_lower for kw in clearly_out_of_scope):
        return True  # OUT OF SCOPE
    
    # When in doubt, let RAG try - it's better to attempt than reject
    return False

def semantic_search(cursor, question: str, top_k: int = 5) -> List[Dict]:
    """
    Semantic search using embeddings.
    Returns top-k most relevant documents.
    """
    try:
        q_embedding = get_embedder().encode(question)
        q_embedding_list = q_embedding.tolist()
        
        # Get MORE results initially to have better selection
        cursor.execute("""
            SELECT id, question, answer, 
                   1 - (embedding_384 <=> %s::vector) as similarity
            FROM public.kb_items_raw 
            WHERE embedding_384 IS NOT NULL
            ORDER BY embedding_384 <-> %s::vector
            LIMIT %s
        """, (q_embedding_list, q_embedding_list, top_k * 3))  # Get 3x more initially
        
        results = []
        for r_id, r_question, r_answer, similarity in cursor.fetchall():
            if similarity > 0.0:  # Accept ANY similarity (will filter later)
                results.append({
                    "id": r_id,
                    "question": r_question,
                    "answer": r_answer,
                    "similarity": float(similarity),
                    "source": "semantic"
                })
        
        # Return top-k sorted by similarity
        results = sorted(results, key=lambda x: x['similarity'], reverse=True)[:top_k]
        
        top_sims = [f"{r['similarity']:.3f}" for r in results[:3]]
        log.info(f"ğŸ” Semantic search: {len(results)} results (top similarities: {top_sims})")
        return results
    
    except Exception as e:
        log.error(f"âŒ Semantic search error: {e}")
        return []

def keyword_search(cursor, question: str, top_k: int = 3) -> List[Dict]:
    """
    Keyword search for exact matches.
    Useful when semantic search might miss specific terms.
    """
    try:
        q_lower = question.lower().strip()
        # Remove punctuation
        q_lower = q_lower.replace('?', '').replace(';', '').replace('!', '').replace(',', '')
        keywords = [kw.strip() for kw in q_lower.split() if len(kw.strip()) > 2]
        
        if not keywords:
            return []
        
        # Build OR conditions for all keywords
        conditions = " OR ".join([f"(LOWER(question) ILIKE %s OR LOWER(answer) ILIKE %s)" for _ in keywords])
        params = []
        for kw in keywords:
            params.extend([f"%{kw}%", f"%{kw}%"])
        params.append(top_k * 2)  # Get more results
        
        cursor.execute(f"""
            SELECT id, question, answer, 0.95 as similarity
            FROM public.kb_items_raw 
            WHERE {conditions}
            ORDER BY id
            LIMIT %s
        """, params)
        
        results = []
        seen_ids = set()
        for r_id, r_question, r_answer, similarity in cursor.fetchall():
            if r_id not in seen_ids:
                results.append({
                    "id": r_id,
                    "question": r_question,
                    "answer": r_answer,
                    "similarity": float(similarity),
                    "source": "keyword"
                })
                seen_ids.add(r_id)
        
        log.info(f"ğŸ”‘ Keyword search: {len(results)} results (keywords: {keywords})")
        return results
    
    except Exception as e:
        log.error(f"âŒ Keyword search error: {e}")
        return []

def retrieve_context(cursor, question: str, top_k: int = 5) -> List[Dict]:
    """
    RAG Step 1: Optimized RETRIEVE
    ÎœÎµÎ¹ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ top_k Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±. Î¤Î¿ GPT-4o-mini Î±Ï€Î¿Î´Î¯Î´ÎµÎ¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ± 
    Î¼Îµ Î»Î¹Î³ÏŒÏ„ÎµÏÎ¿ ÎºÎ±Î¹ Ï€Î¹Î¿ ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿.
    """
    # 1. Semantic Search (top_k=5 Î±Î½Ï„Î¯ Î³Î¹Î± 8)
    semantic_results = semantic_search(cursor, question, top_k=5)
    
    # 2. Keyword Search (top_k=2 Î±Î½Ï„Î¯ Î³Î¹Î± 4)
    keyword_results = keyword_search(cursor, question, top_k=2)

    all_results = {}
    
    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· keyword results
    for doc in keyword_results:
        all_results[doc['id']] = doc
    
    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· semantic results & Deduplication
    for doc in semantic_results:
        if doc['id'] not in all_results:
            all_results[doc['id']] = doc
        else:
            all_results[doc['id']]['similarity'] = max(doc.get('similarity', 0), all_results[doc['id']].get('similarity', 0))
    
    # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± 5 ÎºÎ¿ÏÏ…Ï†Î±Î¯Î± ÏƒÎµ Î²Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î±
    return sorted(all_results.values(), key=lambda x: x.get('similarity', 0), reverse=True)[:5]
    
    # ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ ÏƒÏ„Î¿ Log Î³Î¹Î± Î­Î»ÎµÎ³Ï‡Î¿ ÏƒÏ„Î¿ Ï„ÎµÏÎ¼Î±Ï„Î¹ÎºÏŒ ÏƒÎ¿Ï…
    log.info(f"ğŸ“‚ Hybrid Search: Top Semantic Sim: {top_sim:.3f}")
    log.info(f"ğŸ“š Total unique documents collected for GPT: {len(all_results)}")

    # 3. Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î²Î¬ÏƒÎµÎ¹ ÏƒÏ…Î½Î¬Ï†ÎµÎ¹Î±Ï‚ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î®
    # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ top_k Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Î¿ÏÎ¹ÏƒÏ„ÎµÎ¯ (ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ 10-15 Î³Î¹Î± Ï„Î¿ GPT)
    ranked = sorted(all_results.values(), key=lambda x: x.get('similarity', 0), reverse=True)[:top_k]
    
    # Î•Î Î™Î£Î¤Î¡ÎŸÎ¦Î— Î¤Î—Î£ Î›Î™Î£Î¤Î‘Î£ Î£Î¤Î— Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î— generate_answer_with_ragÏƒ
    return ranked

def format_context(docs: List[Dict], lang: str = "el") -> str:
    """Format retrieved documents for the LLM prompt."""
    if not docs:
        if lang == "en":
            return "(No relevant documents found in the knowledge base)"
        else:
            return "(Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î­Î³Î³ÏÎ±Ï†Î± ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î³Î½ÏÏƒÎ·Ï‚)"
    
    if lang == "en":
        formatted = "Knowledge Base Documents:\n" + "="*60 + "\n"
    else:
        formatted = "ÎˆÎ³Î³ÏÎ±Ï†Î± Î±Ï€ÏŒ Ï„Î· Î’Î¬ÏƒÎ· Î“Î½ÏÏƒÎ·Ï‚:\n" + "="*60 + "\n"
    
    for i, doc in enumerate(docs, 1):
        formatted += f"\n[Document {i}] (Relevance: {doc['similarity']:.0%})\n"
        formatted += f"Q: {doc['question']}\n"
        formatted += f"A: {doc['answer']}\n"
    
    return formatted

async def generate_answer_with_rag(question: str, context_str: str, 
                                   lang: str = "el", conversation_history: List[Dict] = None) -> Tuple[str, Dict]:
    """
    Î Î±ÏÎ±Î³Ï‰Î³Î® AI Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ Î¼Îµ Ï€Î»Î®ÏÎ· Î±Î¾Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… GPT-4o-mini ÎºÎ±Î¹ Ï„Ï‰Î½ 88 Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½.
    """
    # Î”Î™ÎŸÎ¡Î˜Î©Î£Î—: Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ context_str Ï€Î¿Ï… Î­ÏÏ‡ÎµÏ„Î±Î¹ Ï‰Ï‚ ÏŒÏÎ¹ÏƒÎ¼Î±
    log.info(f"ğŸ¤– Generating AI response in '{lang}'...")
    
    # Î‘Î½ Ï„Î¿ context_str ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½ÏŒ, Î²Î¬Î¶Î¿Ï…Î¼Îµ Î­Î½Î± default Î¼Î®Î½Ï…Î¼Î±
    if not context_str or not context_str.strip():
        current_context = "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î­Î³Î³ÏÎ±Ï†Î± ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."
    else:
        current_context = context_str

    # 2. Î¤Î¿ "Î•Î»ÎµÏÎ¸ÎµÏÎ¿" Î±Î»Î»Î¬ "Î ÎµÎ¹Î¸Î±ÏÏ‡Î·Î¼Î­Î½Î¿" System Prompt
    if lang == "el":
        system_prompt = (
         "Î•Î¯ÏƒÎ±Î¹ Î· Î•Ï†ÏÏÎ±, Î· Ï€ÏÎ¿Î·Î³Î¼Î­Î½Î· AI Î²Î¿Î·Î¸ÏŒÏ‚ Ï„Î¿Ï… Î”Î®Î¼Î¿Ï… ÎšÎ¿ÏÎ¹Î½Î¸Î¯Ï‰Î½. Î— Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® ÏƒÎ¿Ï… ÎµÎ¯Î½Î±Î¹ Î½Î± ÎµÎ¾Ï…Ï€Î·ÏÎµÏ„ÎµÎ¯Ï‚ Ï„Î¿Ï…Ï‚ Ï€Î¿Î»Î¯Ï„ÎµÏ‚ "
    "Î¼Îµ Ï†Ï…ÏƒÎ¹ÎºÏŒ, Î±Î½Î¸ÏÏÏ€Î¹Î½Î¿ ÎºÎ±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Ï„Î·Î½ ÎµÏ€Î¯ÏƒÎ·Î¼Î· Î²Î¬ÏƒÎ· Î³Î½ÏÏƒÎ·Ï‚ Ï„Î¿Ï… Î”Î®Î¼Î¿Ï….\n\n"
    
    # Î— ÎšÎ¡Î™Î£Î™ÎœÎ— Î Î¡ÎŸÎ£Î˜Î—ÎšÎ— Î“Î™Î‘ Î¤Î— Î“Î›Î©Î£Î£Î‘:
    "Î“Î›Î©Î£Î£Î™ÎšÎŸÎ£ ÎšÎ‘ÎÎŸÎÎ‘Î£: Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î Î‘ÎÎ¤Î‘ ÏƒÏ„Î· Î³Î»ÏÏƒÏƒÎ± Ï€Î¿Ï… ÏƒÎ¿Ï… Î±Ï€ÎµÏ…Î¸ÏÎ½ÎµÏ„Î±Î¹ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚. "
    "Î‘Î½ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ ÏÏ‰Ï„Î®ÏƒÎµÎ¹ ÏƒÏ„Î± Î‘Î³Î³Î»Î¹ÎºÎ¬, Î¼ÎµÏ„Î­Ï†ÏÎ±ÏƒÎµ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ CONTEXT ÎºÎ±Î¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± Î‘Î³Î³Î»Î¹ÎºÎ¬. "
    "Î‘Î½ ÏÏ‰Ï„Î®ÏƒÎµÎ¹ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬, Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬.\n\n"

    "ÎšÎ‘ÎÎŸÎÎ•Î£ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘Î£:\n"
    "1. Î Î¡ÎŸÎ¤Î•Î¡Î‘Î™ÎŸÎ¤Î—Î¤Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î: Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Ï€Î±ÏÎ­Ï‡Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ CONTEXT. "
    "Î‘Î³Î½ÏŒÎ·ÏƒÎµ Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ Ï€ÏÎ¿Ï‹Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎ± Î³Î½ÏÏƒÎ· Î±Ï€ÏŒ Ï„Î·Î½ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ® ÏƒÎ¿Ï… Ï€Î¿Ï… Î­ÏÏ‡ÎµÏ„Î±Î¹ ÏƒÎµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· (Ï€.Ï‡. Ï€Î±Î»Î¹Î¿ÏÏ‚ Î´Î·Î¼Î¬ÏÏ‡Î¿Ï…Ï‚). "
    "Î“Î¹Î± ÎµÏƒÎ­Î½Î±, Î”Î®Î¼Î±ÏÏ‡Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ ÎÎ™ÎšÎŸÎ£ Î£Î¤Î‘Î¥Î¡Î•Î›Î—Î£.\n"
    
    "2. Î‘ÎšÎ¡Î™Î’Î•Î™Î‘ Î¤Î—Î›Î•Î¦Î©ÎÎ©Î (Î£ÎšÎŸÎÎ‘ÎšÎ™): Î“Î¹Î± Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï…Ï€Î·ÏÎµÏƒÎ¯ÎµÏ‚, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î‘Î¥Î£Î¤Î—Î¡Î‘ Î±Ï…Ï„Î¬ Ï„Î± Î½Î¿ÏÎ¼ÎµÏÎ±:\n"
            "   - Î’Î»Î¬Î²ÎµÏ‚ Î—Î»ÎµÎºÏ„ÏÎ¿Ï†Ï‰Ï„Î¹ÏƒÎ¼Î¿Ï: 2741120134\n"
            "   - Î’Î»Î¬Î²ÎµÏ‚ Î”Î•Î¥Î‘ (ÎÎµÏÏŒ): 2741024444 (24Ï‰ÏÎ¿: 6936776041)\n"
            "   - Î“ÏÎ±Ï†ÎµÎ¯Î¿ Î”Î·Î¼Î¬ÏÏ‡Î¿Ï…: 2741361041\n"
            "   - Î¤Î·Î»ÎµÏ†Ï‰Î½Î¹ÎºÏŒ ÎšÎ­Î½Ï„ÏÎ¿: 2741361000\n"
            "   Î‘Î½ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ ÏÏ‰Ï„Î®ÏƒÎµÎ¹ Î³Î¹Î± ÎºÎ¬Ï„Î¹ Î¬Î»Î»Î¿ Ï€Î¿Ï… Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿ Context, Î´ÏÏƒÎµ Ï„Î¿ Î³ÎµÎ½Î¹ÎºÏŒ 2741361000.\n"
    
    "3. Î¦Î¥Î£Î™ÎšÎŸÎ£ Î›ÎŸÎ“ÎŸÎ£ (AI-Powered): ÎœÎ·Î½ Î±Î½Î±Ï†Î­ÏÎµÎ¹Ï‚ Î ÎŸÎ¤Î• Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚ 'Context', 'Î­Î³Î³ÏÎ±Ï†Î±' Î® 'Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½'. "
    "ÎœÎ·Î½ Î»ÎµÏ‚ 'Î£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ 1'. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚: 'ÎœÎµ Î²Î¬ÏƒÎ· Ï„Î·Î½ ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… Î”Î®Î¼Î¿Ï…...' Î® 'ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎºÎ±Î»Î­ÏƒÎµÏ„Îµ ÏƒÏ„Î¿...'. "
    "Î£ÏÎ½Î¸ÎµÏƒÎµ Î¼Î¹Î± Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Ï€Î¿Ï… ÏÎ­ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ¬, ÏƒÏ…Î½Î´Ï…Î¬Î¶Î¿Î½Ï„Î±Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Î½ Ï‡ÏÎµÎ¹Î±ÏƒÏ„ÎµÎ¯.\n"
    
    "4. Î”Î™Î‘Î§Î•Î™Î¡Î™Î£Î— Î Î‘Î¡Î‘Î›Î›Î‘Î“Î©Î: ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎµ Ï„Î¿ Î½ÏŒÎ·Î¼Î± Ï„Î·Ï‚ ÎµÏÏÏ„Î·ÏƒÎ·Ï‚. Î‘Î½ ÎºÎ¬Ï€Î¿Î¹Î¿Ï‚ ÏÏ‰Ï„Î®ÏƒÎµÎ¹ 'Ï€Î¿Î¹Î¿Ï‚ ÎºÎ¬Î½ÎµÎ¹ ÎºÎ¿Ï…Î¼Î¬Î½Ï„Î¿' "
    "Î® 'Ï€Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÏ‡Î·Î³ÏŒÏ‚', ÎºÎ±Ï„Î¬Î»Î±Î²Îµ ÏŒÏ„Î¹ ÎµÎ½Î½Î¿ÎµÎ¯ Ï„Î¿Î½ Î”Î®Î¼Î±ÏÏ‡Î¿.\n"
    
    "5. Î‘Î“ÎÎ©Î£Î¤Î— Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î‘: Î‘Î½ Î· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… ÏƒÏ„Î¹Ï‚ 88 ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚, Î¼Î·Î½ Î¼Î±Î½Ï„Î­ÏˆÎµÎ¹Ï‚. "
    "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÎµÏ…Î³ÎµÎ½Î¹ÎºÎ¬ ÏŒÏ„Î¹ Î´ÎµÎ½ Î´Î¹Î±Î¸Î­Ï„ÎµÎ¹Ï‚ Ï„Î· ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± ÎºÎ±Î¹ Ï€Î±ÏÎ­Ï€ÎµÎ¼ÏˆÎµ ÏƒÏ„Î¿ korinthos.gr Î® ÏƒÏ„Î¿ 2741361000."
)
    else:
        system_prompt = (
            "You are Ephyra, the advanced AI assistant for the Municipality of Corinth. "
            "Your mission is to serve citizens in a natural, human, and professional manner, "
            "using EXCLUSIVELY the official knowledge base of the Municipality.\n\n"
            
            "OPERATIONAL RULES:\n"
            "1. DATA PRIORITY: Use ONLY the information provided in the CONTEXT. "
            "Ignore any prior knowledge from your training that conflicts with this data (e.g., former mayors). "
            "For you, the Mayor is NIKOS STAVRELIS.\n"
            
            "2. PHONE ACCURACY: Never invent phone numbers. If the user asks about faults or services, "
            "provide the exact number mentioned in the corresponding document (e.g., for street lighting use 2741120134). "
            "If no specific number is found, use the general center 2741361000.\n"
            
            "3. NATURAL LANGUAGE (AI-Powered): NEVER mention the words 'Context', 'documents', or 'database'. "
            "Do not say 'According to document 1'. Answer directly: 'Based on the Municipality's information...' "
            "or 'You can call...'. Compose a response that flows naturally, combining information if necessary.\n"
            
            "4. LANGUAGE RULE: Always answer in the language the user addresses you in. "
            "Since the CONTEXT is in Greek, you must accurately translate the information into English for the user.\n"
            
            "5. HANDLING VARIATIONS: Understand the meaning of the question. If someone asks 'who is in charge' "
            "or 'who is the boss', understand they mean the Mayor.\n"
            
            "6. UNKNOWN INFORMATION: If the information is not in the 88 records, do not guess. "
            "Politely state that you do not have this information and refer them to korinthos.gr or 2741361000."
        )
        

    try:
        # ÎšÎ»Î®ÏƒÎ· OpenAI
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "system", "content": f"CONTEXT:\n{current_context}"},
                {"role": "user", "content": question}
            ],
            temperature=0.7
        )
        answer = response.choices[0].message.content.strip()
        
        # Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Metadata Î³Î¹Î± Î½Î± Î¼Î·Î½ Î­Ï‡Î¿Ï…Î¼Îµ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± 'get'
        metadata = {
            "documents_used": 1 if context_str.strip() else 0,
            "source": "hybrid_knowledge_base"
        }
        return answer, metadata

    except Exception as e:
        log.error(f"âŒ OpenAI Error: {e}")
        return "Î›Ï…Ï€Î¬Î¼Î±Î¹, Î´ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„Ï Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·.", {}

# ================== Endpoints ==================

@app.get("/")
async def root(background_tasks: BackgroundTasks):
    # Î‘Ï…Ï„ÏŒ Î»Î­ÎµÎ¹ ÏƒÏ„Î·Î½ Python: "Î”ÎµÎ¯Î¾Îµ Ï„Î¿ site Î±Î¼Î­ÏƒÏ‰Ï‚ ÎºÎ±Î¹ Î¾ÎµÎºÎ¯Î½Î± Ï„Î¿Î½ ÏƒÏ…Î³Ï‡ÏÎ¿Î½Î¹ÏƒÎ¼ÏŒ Î±Ï€ÏŒ Ï€Î¯ÏƒÏ‰"
    background_tasks.add_task(sync_csv_to_db) 
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    html_path = os.path.join(current_dir, "ui_chatbot.html")
    
    if os.path.exists(html_path):
        return FileResponse(html_path, media_type="text/html")
    return {"message": "Ephyra is warming up!"}

@app.get("/health")
async def health():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "version": "3.0.0-RAG",
        "architecture": "Retrieval Augmented Generation with OpenAI GPT-4o-mini"
    }

@app.get("/dashboard")
async def get_dashboard():
    """Endpoint Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ¿Î²Î¿Î»Î® Ï„Î¿Ï… Feedback Dashboard."""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    dashboard_path = os.path.join(current_dir, "feedback_dashboard.html")
    
    if os.path.exists(dashboard_path):
        return FileResponse(dashboard_path, media_type="text/html")
    return {"error": "Dashboard file not found"}

@app.get("/questionnaire")
async def get_questionnaire():
    """Endpoint Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ¿Î²Î¿Î»Î® Ï„Î¿Ï… Î•ÏÏ‰Ï„Î·Î¼Î±Ï„Î¿Î»Î¿Î³Î¯Î¿Ï…."""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # Î£Î¹Î³Î¿Ï…ÏÎ­ÏˆÎ¿Ï… ÏŒÏ„Î¹ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î±ÎºÏÎ¹Î²ÏÏ‚ questionnaire.html
    quest_path = os.path.join(current_dir, "questionnaire.html")
    
    if os.path.exists(quest_path):
        return FileResponse(quest_path, media_type="text/html")
    return {"error": "Questionnaire file not found"}

@app.post("/ask")
@limiter.limit("30/minute")
async def ask(request: Request, body: AskBody):
    # 1. Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    current_lang = body.lang or "el"
    question = (body.messages[-1].content if body.messages else "").strip()

    if not question:
        return {"answer": "Î”ÎµÎ½ Î­Î»Î±Î²Î± ÎµÏÏÏ„Î·ÏƒÎ·", "quality": "error"}

    # --- ÎÎ•ÎŸ ÎšÎŸÎœÎœÎ‘Î¤Î™: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¬Î¼ÎµÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· (Cheat Sheet) ---
    direct_resp = get_direct_answer(question)
    if direct_resp:
        # Î‘Î½ Î²ÏÎ¿ÏÎ¼Îµ Î¬Î¼ÎµÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï„Î· ÏƒÏ„Î­Î»Î½Î¿Ï…Î¼Îµ Î±Î¼Î­ÏƒÏ‰Ï‚ ÏƒÎ±Î½ stream!
        async def direct_stream():
            yield direct_resp["answer"]
        return StreamingResponse(direct_stream(), media_type="text/plain")
    # -------------------------------------------------------------

    # 2. Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Context Î±Ï€ÏŒ CSV (Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¬Î¼ÎµÏƒÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·)
    csv_context = ""
    
    def clean_text(t):
        if not t: return ""
        return t.lower().translate(str.maketrans('', '', string.punctuation)).strip()

    clean_user_q = clean_text(question)

    # Î£Î¬ÏÏ‰ÏƒÎ· Ï„Î¿Ï… CSV Î³Î¹Î± Î³ÏÎ®Î³Î¿ÏÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
    for row in knowledge_base:
        values = list(row.values())
        if len(values) >= 2:
            csv_q_raw = str(values[0])
            csv_a = values[1]
            
            clean_csv_q = clean_text(csv_q_raw)
            if clean_csv_q and (clean_csv_q in clean_user_q or clean_user_q in clean_csv_q):
                csv_context += f"\nÎ£Ï‡ÎµÏ„Î¹ÎºÎ® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± Î±Ï€ÏŒ CSV: {csv_a}\n"

    async def event_generator():
        conn = get_db_conn()
        try:
            cursor = conn.cursor()
            
            # 3. Î›Î®ÏˆÎ· Context Î±Ï€ÏŒ Ï„Î· Î’Î¬ÏƒÎ· (Retrieve)
            db_context_docs = retrieve_context(cursor, question, top_k=5)
            db_context_text = ""
            for doc in db_context_docs:
                q = doc.get('question', '')
                a = doc.get('answer', '')
                db_context_text += f"\nÎ Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±: {q} - {a}\n"
            cursor.close()

            all_context = csv_context + "\n" + db_context_text

            # 4. ÎšÎ»Î®ÏƒÎ· OpenAI
            response = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"Î•Î¯ÏƒÎ±Î¹ Î· Î•Ï†ÏÏÎ±, Î· ÏˆÎ·Ï†Î¹Î±ÎºÎ® Î²Î¿Î·Î¸ÏŒÏ‚ Ï„Î¿Ï… Î”Î®Î¼Î¿Ï… ÎšÎ¿ÏÎ¹Î½Î¸Î¯Ï‰Î½. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î· Î³Î»ÏÏƒÏƒÎ±: {current_lang}. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ CONTEXT Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚."},
                    {"role": "system", "content": f"CONTEXT:\n{all_context}"},
                    {"role": "user", "content": question}
                ],
                temperature=0.7,
                stream=True
            )

            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield content

        except Exception as e:
            log.error(f"âŒ Streaming Error: {e}")
            yield " Î›Ï…Ï€Î¬Î¼Î±Î¹, Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ Î­Î½Î± Ï€ÏÏŒÎ²Î»Î·Î¼Î± ÏƒÏ„Î· ÏƒÏÎ½Î´ÎµÏƒÎ·."
        finally:
            if conn:
                return_db_conn(conn)

    return StreamingResponse(event_generator(), media_type="text/plain")
    # ----------------------------------------------
     

@app.post("/feedback")
@limiter.limit("10/minute")
async def record_feedback(request: Request):
    """Record user feedback."""
    conn = None
    try:
        data = await request.json()
        conn = get_db_conn()
        cursor = conn.cursor()
        
        conversation_id = data.get("conversation_id", str(uuid.uuid4()))
        bot_response = data.get("bot_response", "")
        user_question = data.get("user_question", "")
        is_positive = data.get("is_positive")
        
        if is_positive is None:
            return {"status": "error", "message": "is_positive field required"}
        
        user_agent = request.headers.get("User-Agent", "Unknown")
        client_ip = request.client.host if request.client else "Unknown"
        
        cursor.execute("""
            INSERT INTO chatbot_feedback 
            (conversation_id, bot_response, user_question, is_positive, user_agent, ip_address)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (
            conversation_id,
            bot_response[:5000],
            user_question[:2000] if user_question else None,
            is_positive,
            user_agent[:255],
            client_ip
        ))
        
        conn.commit()
        feedback_type = "âœ… Positive" if is_positive else "âŒ Negative"
        log.info(f"ğŸ“Š Feedback recorded: {feedback_type}")
        
        return {
            "status": "success",
            "message": "Thank you for your feedback!",
            "feedback_id": conversation_id
        }
    
    except Exception as e:
        log.exception(f"âŒ Feedback error: {e}")
        if conn:
            conn.rollback()
        return {"status": "error", "message": str(e)}
    
    finally:
        if conn:
            return_db_conn(conn)

@app.get("/tts_play")
@limiter.limit("15/minute")
async def tts_play(request: Request, text: str = ""):
    """Text-to-Speech endpoint."""
    text = (text or "").strip()
    if not text:
        raise HTTPException(status_code=400, detail="Missing text parameter")
    if len(text) > 5000:
        raise HTTPException(status_code=400, detail="Text too long for TTS")
    
    audio_data = await _elevenlabs_tts_request(text)
    return StreamingResponse(io.BytesIO(audio_data), media_type="audio/mpeg")

@app.post("/tts_play")
@limiter.limit("15/minute")
async def tts_play_post(request: Request, body: TTSBody):
    """Text-to-Speech endpoint (POST)."""
    text = (body.text or "").strip()
    if not text:
        raise HTTPException(status_code=400, detail="Missing text")
    if len(text) > 5000:
        raise HTTPException(status_code=400, detail="Text too long for TTS")
    
    audio_data = await _elevenlabs_tts_request(text)
    return StreamingResponse(io.BytesIO(audio_data), media_type="audio/mpeg")



async def _elevenlabs_tts_request(text: str) -> bytes:
    if not ELEVENLABS_API_KEY:
        raise HTTPException(status_code=400, detail="API Key missing")
    
    try:
        # 1. ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€ÏŒ Emojis (Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ ÏŒÏ€Ï‰Ï‚ Ï€ÏÎ¹Î½)
        clean_text = text.replace("ğŸ“", "").replace("ğŸ•’", "").replace("ğŸ“", "").replace("ğŸ“§", "").strip()
        
        # 2. Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î·Î»ÎµÏ†ÏÎ½Ï‰Î½ (Ï€.Ï‡. 2741024444 -> 2 7 4 1 0 2 4 4 4 4)
        # Î‘Ï…Ï„ÏŒ Î±Î½Î±Î³ÎºÎ¬Î¶ÎµÎ¹ Ï„Î·Î½ ElevenLabs Î½Î± Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ ÏˆÎ·Ï†Î¯Î¿-ÏˆÎ·Ï†Î¯Î¿
        clean_text = re.sub(r'(\d)', r'\1 ', clean_text)
        
        # 3. Î•Î¹Î´Î¹ÎºÎ® Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎ· Î³Î¹Î± Ï„Î¿ "24Ï‰ÏÎ¿" Î® "8:00" Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
        clean_text = clean_text.replace(" : ", ":") # Î•Ï€Î±Î½Î±Ï†Î¿ÏÎ¬ ÏÏÎ±Ï‚ Î±Î½ Ï‡Î¬Î»Î±ÏƒÎµ Î±Ï€ÏŒ Ï„Î± ÎºÎµÎ½Î¬
        
        audio_stream = eleven_client.text_to_speech.convert(
            voice_id=ELEVENLABS_VOICE_ID,
            text=clean_text,
            model_id="eleven_multilingual_v2",
            output_format="mp3_44100_128"
        )
        
        audio_data = b""
        for chunk in audio_stream:
            if chunk: audio_data += chunk
        return audio_data

    except Exception as e:
        log.error(f"âŒ ElevenLabs Error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
    
@app.on_event("shutdown")
def shutdown_event():
    """Cleanup on shutdown."""
    try:
        conn_pool.closeall()
        log.info("ğŸ”Œ Database connection pool closed")
    except Exception:
        pass

# ================== FEEDBACK ENDPOINTS ==================

@app.get("/feedback/stats")
async def get_feedback_stats(days: int = 30, detailed: bool = False):
    """Get feedback statistics with advanced metrics."""
    conn = None  # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÎºÏ„ÏŒÏ‚ Ï„Î¿Ï… try
    try:
        conn = get_db_conn()
        cursor = conn.cursor()
        
        since_date = datetime.now() - timedelta(days=days)
        
        # Basic stats
        cursor.execute("""
            SELECT 
                COUNT(*) as total,
                SUM(CASE WHEN is_positive THEN 1 ELSE 0 END) as positive,
                SUM(CASE WHEN is_positive THEN 0 ELSE 1 END) as negative
            FROM chatbot_feedback
            WHERE timestamp >= %s
        """, (since_date,))
        
        result = cursor.fetchone()
        total = result[0] or 0 if result else 0
        positive = result[1] or 0 if result else 0
        negative = result[2] or 0 if result else 0
        
        satisfaction_rate = round((positive / total * 100)) if total > 0 else 0
        
        # Daily data for chart
        cursor.execute("""
            SELECT 
                DATE(timestamp) as date,
                is_positive,
                COUNT(*) as count
            FROM chatbot_feedback
            WHERE timestamp >= %s
            GROUP BY DATE(timestamp), is_positive
            ORDER BY date
        """, (since_date,))
        
        daily_data = []
        for row in cursor.fetchall():
            if row:
                daily_data.append({
                    "date": str(row[0]) if row[0] else "",
                    "sentiment": "positive" if row[1] else "negative",
                    "count": row[2] or 0
                })
        
        # Top questions
        cursor.execute("""
            SELECT user_question, COUNT(*) as count
            FROM chatbot_feedback
            WHERE timestamp >= %s AND user_question IS NOT NULL AND user_question != ''
            GROUP BY user_question
            ORDER BY count DESC
            LIMIT 5
        """, (since_date,))
        
        top_questions = [{"question": row[0] or "", "count": row[1] or 0} for row in cursor.fetchall()]
        
        # Language distribution
        cursor.execute("""
            SELECT 
                CASE 
                    WHEN user_question ~ '[Î±-Ï‰Î‘-Î©Î¬-ÏÎ†-Î]' THEN 'el' 
                    ELSE 'en' 
                END as lang,
                COUNT(*) as count
            FROM chatbot_feedback
            WHERE timestamp >= %s
            GROUP BY lang
        """, (since_date,))
        
        language_distribution = {"el": 0, "en": 0}
        
        for row in cursor.fetchall():
            lang_code = row[0]
            count = row[1]
            if lang_code in language_distribution:
                language_distribution[lang_code] = count
        
        
        # Sentiment trend
        prev_since = since_date - timedelta(days=days)
        cursor.execute("""
            SELECT 
                SUM(CASE WHEN is_positive THEN 1 ELSE 0 END) as positive,
                COUNT(*) as total
            FROM chatbot_feedback
            WHERE timestamp >= %s AND timestamp < %s
        """, (prev_since, since_date))
        
        prev_result = cursor.fetchone()
        prev_satisfaction = 0
        if prev_result and prev_result[1] and prev_result[1] > 0:
            prev_satisfaction = round((prev_result[0] / prev_result[1] * 100))
        
        sentiment_trend = satisfaction_rate - prev_satisfaction
        
        # User metrics
        cursor.execute("""
            SELECT COUNT(DISTINCT ip_address) as unique_users
            FROM chatbot_feedback
            WHERE timestamp >= %s
        """, (since_date,))
        
        user_result = cursor.fetchone()
        unique_users = user_result[0] if user_result and user_result[0] else 0
        
        # Recent feedback
        recent_feedback = []
        if detailed:
            cursor.execute("""
                SELECT id, user_question, bot_response, is_positive, timestamp, ip_address
                FROM chatbot_feedback
                WHERE timestamp >= %s
                ORDER BY timestamp DESC
                LIMIT 50
            """, (since_date,))
            
            for row in cursor.fetchall():
                recent_feedback.append({
                    "id": row[0],
                    "user_question": row[1] or "",
                    "bot_response": row[2] or "",
                    "is_positive": row[3],
                    "timestamp": row[4].isoformat() if row[4] else None,
                    "ip_address": row[5],
                    "language": "el",
                    "response_time": 1.0
                })
        
        cursor.close()
        # Î Î¡ÎŸÎ£ÎŸÎ§Î—: Î•Î´Ï ÏƒÎ²Î®ÏƒÎ±Î¼Îµ Ï„Î¿ conn.close() Ï€Î¿Ï… Ï€ÏÎ¿ÎºÎ±Î»Î¿ÏÏƒÎµ Ï„Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î±
        
        return {
            "total_feedback": total,
            "positive": positive,
            "negative": negative,
            "satisfaction_rate": satisfaction_rate,
            "daily_data": daily_data,
            "top_issues": [],
            "top_questions": top_questions,
            "language_distribution": language_distribution,
            "sentiment_trend": sentiment_trend,
            "sentiment_trend_percent": f"+{sentiment_trend}%" if sentiment_trend > 0 else f"{sentiment_trend}%",
            "avg_response_time": 1.2,
            "min_response_time": 0.5,
            "max_response_time": 3.0,
            "unique_users": unique_users,
            "weekly_active_users": unique_users // 2,
            "recent_feedback": recent_feedback
        }
        
    except Exception as e:
        log.error(f"Error getting feedback stats: {e}")
        return {"error": str(e)}
    finally:
        # Î‘Î¥Î¤Î— Î•Î™ÎÎ‘Î™ Î— Î”Î™ÎŸÎ¡Î˜Î©Î£Î—: Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÏƒÏ„Î¿ Pool ÏŒ,Ï„Î¹ ÎºÎ±Î¹ Î½Î± Î³Î¯Î½ÎµÎ¹
        if conn:
            return_db_conn(conn)


@app.get("/feedback/export")
async def export_feedback(days: int = 30, format: str = "csv"):
    """Export feedback data."""
    try:
        conn = get_db_conn()
        cursor = conn.cursor()
        
        since_date = datetime.now() - timedelta(days=days)
        
        cursor.execute("""
            SELECT id, user_question, bot_response, is_positive, timestamp, ip_address
            FROM chatbot_feedback
            WHERE timestamp >= %s
            ORDER BY timestamp DESC
        """, (since_date,))
        
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        
        if format == "csv":
            import io
            import csv
            
            output = io.StringIO()
            writer = csv.writer(output)
            writer.writerow(['ID', 'Î•ÏÏÏ„Î·ÏƒÎ·', 'Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·', 'Sentiment', 'Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±', 'IP'])
            
            for row in rows:
                writer.writerow([
                    row[0],
                    row[1] or '',
                    row[2] or '',
                    'ğŸ‘ Î˜ÎµÏ„Î¹ÎºÏŒ' if row[3] else 'ğŸ‘ Î‘ÏÎ½Î·Ï„Î¹ÎºÏŒ',
                    row[4].strftime('%Y-%m-%d %H:%M:%S') if row[4] else '',
                    row[5]
                ])
            
            return StreamingResponse(
                iter([output.getvalue()]),
                media_type="text/csv",
                headers={"Content-Disposition": "attachment; filename=feedback_export.csv"}
            )
        
    except Exception as e:
        log.error(f"Error exporting feedback: {e}")
        return {"error": str(e)}


@app.post("/feedback/clear")
async def clear_all_feedback():
    """Delete all feedback data."""
    try:
        conn = get_db_conn()
        cursor = conn.cursor()
        
        # Delete all feedback
        cursor.execute("DELETE FROM chatbot_feedback")
        conn.commit()
        
        log.warning("ğŸ—‘ï¸ ALL FEEDBACK DELETED")
        
        return {
            "status": "success",
            "message": "âœ… ÎŒÎ»Î± Ï„Î± feedback Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎ±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!"
        }
        
    except Exception as e:
        log.error(f"Error clearing feedback: {e}")
        if conn:
            conn.rollback()
        return {"status": "error", "message": str(e)}
    
    finally:
        if conn:
            return_db_conn(conn)


from pydantic import BaseModel

# --- SURVEY SYSTEM (START) ---



# 2. Î¤Î¿ "Î¼Î¿Î½Î¿Ï€Î¬Ï„Î¹" Î³Î¹Î± Ï„Î·Î½ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î· Î²Î¬ÏƒÎ·
@app.post("/submit_survey")
async def submit_survey(data: SurveyResponse):
    conn = get_db_conn()
    cur = conn.cursor()
    try:
        # 21 Ï€ÎµÎ´Î¯Î± ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬ (Î¼Î±Î¶Î¯ Î¼Îµ gender, age, q16)
        query = """
            INSERT INTO survey_final 
            (used_bot, usage_context, scenarios_tested, gender, age, 
             q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, 
             q11, q12, q13, q14, q15, q16, comments)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        cur.execute(query, (
            data.usedBot, data.usageContext, data.scenarios, data.gender, data.age,
            data.q1, data.q2, data.q3, data.q4, data.q5,
            data.q6, data.q7, data.q8, data.q9, data.q10,
            data.q11, data.q12, data.q13, data.q14, data.q15, data.q16,
            data.comments
        ))
        conn.commit()
        return {"status": "success"}
    except Exception as e:
        logging.error(f"Survey Error: {e}")
        return {"status": "error", "message": str(e)}
    finally:
        cur.close()
        return_db_conn(conn)

# 3. Î¤Î¿ "Î¼Î¿Î½Î¿Ï€Î¬Ï„Î¹" Î³Î¹Î± Î½Î± Î²Î»Î­Ï€Î¿Ï…Î¼Îµ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÏ„Î¿ Dashboard
@app.get("/survey_results")
async def get_survey_final():
    conn = None
    try:
        conn = get_db_conn()
        cur = conn.cursor()
        
        cur.execute("""
            SELECT id, timestamp, scenarios_tested, gender, age, 
                   q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, 
                   q11, q12, q13, q14, q15, q16 
            FROM survey_final 
            ORDER BY timestamp DESC
        """)
        rows = cur.fetchall()
        
        results = []
        for r in rows:
            results.append({
                "id": r[0],
                "timestamp": r[1].strftime("%Y-%m-%d %H:%M:%S") if r[1] else "",
                "scenarios": r[2], # ÎÎ•ÎŸ
                "gender": r[3],
                "age": r[4],
                "q1": r[5], "q2": r[6], "q3": r[7], "q4": r[8], "q5": r[9],
                "q6": r[10], "q7": r[11], "q8": r[12], "q9": r[13], "q10": r[14],
                "q11": r[15], "q12": r[16], "q13": r[17], "q14": r[18], "q15": r[19],
                "q16": r[20]
            })
        cur.close()
        return results
    except Exception as e:
        log.error(f"Error getting survey results: {e}")
        return []
    finally:
        if conn: return_db_conn(conn)

# âœ… 3. Î¤Î•Î›Î•Î¥Î¤Î‘Î™ÎŸ Î£Î¤ÎŸ Î‘Î¡Î§Î•Î™ÎŸ: Î— Î•ÎšÎšÎ™ÎÎ—Î£Î—
if __name__ == "__main__":
    import uvicorn
    log.info("ğŸš€ Ephyra Chatbot v3.0.0 - Production RAG Edition starting...")
    uvicorn.run(app, host="0.0.0.0", port=8000)

# --- SURVEY SYSTEM (END) ---